{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\Lab716A-PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nltk.corpus.gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = dataset.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2621613"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51156"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chars = len(dataset.raw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11793318"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = dataset.raw()[: n_chars // 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {}\n",
    "idx2char = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in dataset.raw():\n",
    "    if c in char2idx:\n",
    "        continue\n",
    "    idx2char.append(c)\n",
    "    char2idx[c] = len(idx2char) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'E', 'm', 'a', ' ', 'b', 'y', 'J', 'n', 'e']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Emma by Jane Austen 1816]\\n\\nVOLUME I\\n\\nCHAPTER I\\n\\n\\nEmma Woodhouse, handsome, clever, and rich, with a'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.raw()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.9\n",
    "train_data = dataset.raw()[:int(0.7*len(dataset.raw()))]\n",
    "valid_data = dataset.raw()[int(0.7*len(dataset.raw())):]\n",
    "seq_len = 50\n",
    "batch_size = 20\n",
    "n_seq = len(train_data)//seq_len\n",
    "X_train = np.zeros((n_seq*seq_len, len(idx2char)), dtype = np.short)\n",
    "Y_train = np.zeros_like(X_train)\n",
    "for i in range(n_seq*seq_len):\n",
    "    c = train_data[i]\n",
    "    X_train[i][char2idx[c]] = 1\n",
    "\n",
    "for i in range(1, n_seq*seq_len + 1):\n",
    "    c = train_data[i]\n",
    "    Y_train[i - 1][char2idx[c]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train\n",
    "X_train = X_train.reshape(-1, seq_len, len(idx2char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165106, 50, 97)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train\n",
    "Y_train = Y_train.reshape(-1, seq_len, len(idx2char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165106, 50, 97)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X_train, Y_train, batch_size):\n",
    "    n = X_train.shape[0]\n",
    "    idx = np.random.randint(0, n, batch_size)\n",
    "    out = (X_train[idx], Y_train[idx])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = get_batch(X_train, Y_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 50])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.tensor(labels), dim = 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 50, 97) (20, 50, 97)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \"Batch-first Elman RNN\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, non_linearity):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size = input_size, hidden_size = hidden_size,\n",
    "                          num_layers = num_layers, nonlinearity = non_linearity,\n",
    "                          bias = True, batch_first=True, dropout=0, bidirectional=False)\n",
    "        self.Who = nn.Linear(hidden_size, input_size)\n",
    "    \n",
    "    def forward(self, X, h=None):\n",
    "        if h is not None:\n",
    "            features, h = self.rnn(X, h)\n",
    "        else:\n",
    "            features, h = self.rnn(X)\n",
    "        out = self.Who(features)\n",
    "        return out, h\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"Batch-first LSTM\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size = input_size, hidden_size = hidden_size,\n",
    "                          num_layers = num_layers, bias = True,\n",
    "                          batch_first=True, dropout=0, bidirectional=False)\n",
    "        self.Who = nn.Linear(hidden_size, input_size)\n",
    "    \n",
    "    def forward(self, X, h=None):\n",
    "        if h is not None:\n",
    "            features, h = self.rnn(X, h)\n",
    "        else:\n",
    "            features, h = self.rnn(X)\n",
    "        out = self.Who(features)\n",
    "        return out, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, init_char, char2idx, idx2char, n_chars):\n",
    "    x = np.zeros((num_layers, 1, len(char2idx)), dtype = np.float)\n",
    "    h = np.zeros((num_layers, 1, hidden_dim), dtype = np.float)\n",
    "    h = torch.tensor(h).to(device)\n",
    "    x[0, 0, char2idx[init_char]] = 1\n",
    "    x = torch.tensor(x).to(device)\n",
    "    gen = [init_char]\n",
    "    for i in range(n_chars):\n",
    "        out, h = model(x, h)\n",
    "        probs = torch.softmax(out, dim = 2).detach().cpu().numpy()\n",
    "        char = np.random.choice(idx2char, p = np.squeeze(probs))\n",
    "        gen.append(char)\n",
    "        x = np.zeros((1, 1, len(char2idx)), dtype = np.float)\n",
    "        x[0, 0, char2idx[char]] = 1\n",
    "        x = torch.tensor(x).to(device)\n",
    "    return ''.join(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_LSTM(model, init_char, char2idx, idx2char, n_chars):\n",
    "    x = np.zeros((1, 1, len(char2idx)), dtype = np.float)\n",
    "    h = np.zeros((1, 1, hidden_dim), dtype = np.float)\n",
    "    c = np.zeros((1, 1, hidden_dim), dtype = np.float)\n",
    "    h = torch.tensor(h).to(device)\n",
    "    c = torch.tensor(c).to(device)\n",
    "    x[0, 0, char2idx[init_char]] = 1\n",
    "    x = torch.tensor(x).to(device)\n",
    "    gen = [init_char]\n",
    "    for i in range(n_chars):\n",
    "        out, (h, c) = model(x.float(), (h, c))\n",
    "        probs = torch.softmax(out, dim = 2).detach().cpu().numpy()\n",
    "        char = np.random.choice(idx2char, p = np.squeeze(probs))\n",
    "        gen.append(char)\n",
    "        x = np.zeros((1, 1, len(char2idx)), dtype = np.float)\n",
    "        x[0, 0, char2idx[char]] = 1\n",
    "        x = torch.tensor(x).to(device)\n",
    "    return ''.join(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(idx2char)\n",
    "hidden_dim = 128\n",
    "num_layers = 1\n",
    "model = LSTM(input_size, hidden_dim, num_layers)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss_vals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, avg loss = 3.31\n",
      "aD1mef\n",
      "\"y\" yonwe\n",
      "LeronOrtt\n",
      "sn1Oter:e , raalbeS uhn a rdhd  lt n oeiep\n",
      "etud p:d rei0 a\n",
      "ber\"metindt  wb\n",
      "\n",
      "\n",
      "Epoch = 2, avg loss = 2.88\n",
      "agh ute hdkseAriutpeurhd abl5 sep-rentoud:i\n",
      "Acm ly ies Da,d un  orrd andt fleagby yisenotoeeobaud tte\n",
      "\n",
      "\n",
      "Epoch = 3, avg loss = 2.56\n",
      "ad ngrmouf tha ic.  These axrss and blt ttfo an, tsn govar alr eup woaiitho Miy enror.\n",
      "a:\n",
      "1::4  the s\n",
      "\n",
      "\n",
      "Epoch = 4, avg loss = 2.43\n",
      "aeginef nai aavg ant lllat faindidne.\n",
      "on hout s ind oou Lote hog wotnginde s irller ar the? Ass,aw th\n",
      "\n",
      "\n",
      "Epoch = 5, avg loss = 2.36\n",
      "at ha in th to hay werk the \n",
      "ramle\"\n",
      "roy plain she t.e the int welll.n zold saroeed shan, matr whawst\n",
      "\n",
      "\n",
      "Epoch = 6, avg loss = 2.3\n",
      "a ah, ad thPRoy thoas, os the I in tfou sars git hik thitlid worthes seanks\n",
      "soise hos tnallreg eewaw,\n",
      "\n",
      "\n",
      "Epoch = 7, avg loss = 2.24\n",
      "a\n",
      "mok wamlenaray,\n",
      "al  whan mo brot theu 1alp boathes, the: I bougnengted\n",
      "ande th pish fort; Myens\"ris\n",
      "\n",
      "\n",
      "Epoch = 8, avg loss = 2.2\n",
      "aL\n",
      "was minger.\n",
      "\n",
      "A:\n",
      "2R F aLnd cliid of the moul, whed \"be he cor bot urlasife and\n",
      "om out it he thims, \n",
      "\n",
      "\n",
      "Epoch = 9, avg loss = 2.18\n",
      "arty lingchoug,\n",
      "fthiy sford; an the dad bre hardcly hist toufito igatot circolughe mik you .\n",
      " I  o I \n",
      "\n",
      "\n",
      "Epoch = 10, avg loss = 2.15\n",
      "al for the lyout\n",
      "net aly ther. LORDpbore thist it Iver of hey epowmrkimo,\n",
      "\n",
      "a the pominebd.  o seaS \n",
      "\n",
      "\n",
      "Epoch = 11, avg loss = 2.11\n",
      "atg salf\", Iro mo tna touse; and nou inen in m\"Icoinguth mewen; and hasnthing to pable the that nou',\n",
      "\n",
      "\n",
      "Epoch = 12, avg loss = 2.1\n",
      "aguhed an t8 mly tos moded mis\n",
      " of pae whid lous, ave ceinctennisesthe dimas afithek sok nomy\n",
      "\n",
      "\n",
      "Epoch = 13, avg loss = 2.07\n",
      "an, the cond tham, redso an to further ppremy yo\n",
      "yo sala ar\n",
      "thisher alverly forseghtes thirminth\n",
      "tha\n",
      "\n",
      "\n",
      "Epoch = 14, avg loss = 2.05\n",
      "all note filllt, Buster bo hebransiry alt you, anthatre fath than the yair the Preey, and betersinn t\n",
      "\n",
      "\n",
      "Epoch = 15, avg loss = 2.03\n",
      "am of he oo bote am the hispyor, I able faw the\n",
      "hiss my waos bity soled.\n",
      "\n",
      "8:4 1 Dis meriys\n",
      "d am Ichas\n",
      "\n",
      "\n",
      "Epoch = 16, avg loss = 2.02\n",
      "ath frem thecery, and teall in eles: Ond demreove\n",
      "kontour;.--\n",
      "\n",
      " She shourdn inperos\n",
      "over hupllegntas\n",
      "\n",
      "\n",
      "Epoch = 17, avg loss = 2.0\n",
      "abreri; For\n",
      "ghem, \n",
      "Wind whe some. \n",
      "You s minhowss, and Mppenten Mr\n",
      "anchel.\n",
      "\n",
      "\n",
      "1H:3 At net wist custe h\n",
      "\n",
      "\n",
      "Epoch = 18, avg loss = 1.99\n",
      "ave to Gof, thou to gionted they ratoing of the Loo de Hencaingr upto e yous be faldens, unt tureth i\n",
      "\n",
      "\n",
      "Epoch = 19, avg loss = 1.96\n",
      "a then wet was the forveren, the lefed hiss\n",
      "ley vead.  :5 And But to bu id gryar\n",
      "bustedtly ineadle ca\n",
      "\n",
      "\n",
      "Epoch = 20, avg loss = 1.95\n",
      "ah the was hea to chushow thoubrefolly stall canm; at remiest aningregus\n",
      "ato the son.\n",
      "\n",
      "1:9 And werwe \n",
      "\n",
      "\n",
      "Epoch = 21, avg loss = 1.93\n",
      "at fies.  he bus if, and\n",
      "mlongry\n",
      "by anuz magon, he cash the latl gre with, behrom the cime here, wher\n",
      "\n",
      "\n",
      "Epoch = 22, avg loss = 1.93\n",
      "at is of God, wat of ne wemated enquidaispion into Bertelally as wile peesen.-\n",
      "\n",
      "26:n Theis wish of th\n",
      "\n",
      "\n",
      "Epoch = 23, avg loss = 1.91\n",
      "atnonch to ye live, he: but she scaik: Het is evely madh, and.\n",
      "39:11 For Dijahabiting of yut yer he h\n",
      "\n",
      "\n",
      "Epoch = 24, avg loss = 1.9\n",
      "ast you th we hearlf they shall to with fremale.\"\n",
      "\n",
      "\"If nactlld eve she offresuldeting to my to yo his\n",
      "\n",
      "\n",
      "Epoch = 25, avg loss = 1.9\n",
      "ar spoced unto the iswally woted Zoobentin: and he had. 6 thkyer juaking\n",
      "quiel that an I sunded uf ou\n",
      "\n",
      "\n",
      "Epoch = 26, avg loss = 1.88\n",
      "at kince.  t thened mornastermy\n",
      ", mever tome to some.\n",
      "\n",
      "15:12 And Mash offreistifte. \"The\n",
      "Levider, lea\n",
      "\n",
      "\n",
      "Epoch = 27, avg loss = 1.87\n",
      "ald thas hath nowers of my, and Bosace wastred her on yeur he shall gad as Chrandat!; thately bearen \n",
      "\n",
      "\n",
      "Epoch = 28, avg loss = 1.86\n",
      "atwery your, and\n",
      "then whe of his not onoweth hes.\n",
      "Thil silent now the ruth\n",
      "cunsevering?\n",
      "\n",
      "32:17 And ge\n",
      "\n",
      "\n",
      "Epoch = 29, avg loss = 1.85\n",
      "ath; and who efure my cater of the gett froth\n",
      "hemver of ammacturint of gonder saybiniane sabled\n",
      "hin f\n",
      "\n",
      "\n",
      "Epoch = 30, avg loss = 1.84\n",
      "arearsenop, on hadden, gay his\n",
      "ever it as be thou, he chand best of But the wintord the buked take Mi\n",
      "\n",
      "\n",
      "Epoch = 31, avg loss = 1.85\n",
      "ake of sumenghtine sckiving shome wild the\n",
      "gove the maderets boungus.\n",
      "The chimistle. \n",
      "13:4 When it al\n",
      "\n",
      "\n",
      "Epoch = 32, avg loss = 1.82\n",
      "airs.\n",
      "\n",
      "3:17 Thus Torysherry stowed eaciteded argipate flow has peafaken to Rem, and Davighalt queters\n",
      "\n",
      "\n",
      "Epoch = 33, avg loss = 1.82\n",
      "aly wold praice;\n",
      "his all simpeitiaghesion, if percoot: I wrom griecl with, and live ou\n",
      "doople come so\n",
      "\n",
      "\n",
      "Epoch = 34, avg loss = 1.81\n",
      "and to de theres fool yof a lejtthest fordeching in then, whrey which th; was ho.\n",
      "\n",
      "28:19 Ant comah ex\n",
      "\n",
      "\n",
      "Epoch = 35, avg loss = 1.8\n",
      "all Jerwian.\n",
      "\n",
      " The dand, the soft, the sup, Vasling to all that. The sodr weth all came.\n",
      "\n",
      "26:2\n",
      "If un \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 35\n",
    "n_iters = len(X_train)//(seq_len*batch_size)\n",
    "avg_loss = 0\n",
    "for e in range(n_epochs):\n",
    "    for i in range(n_iters):\n",
    "        data, labels = get_batch(X_train, Y_train, batch_size)\n",
    "        data = torch.tensor(data, dtype = torch.float).to(device)\n",
    "        labels = torch.argmax(torch.tensor(labels), dim = 2)\n",
    "        labels = labels.reshape((-1, ))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out, h = model(data)\n",
    "        logits = out.cpu().reshape(-1, input_size)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        loss.backward(retain_graph = True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_vals.append(loss.item())\n",
    "        avg_loss += loss_vals[-1]\n",
    "    avg_loss /= n_iters\n",
    "    print('Epoch = {}, avg loss = {:.3}'.format(e + 1, avg_loss))\n",
    "    print(sample_LSTM(model, 'a', char2idx, idx2char, 100))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c365d75eb8>]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c363235ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad whiching noo clengiema it, mo\n",
      "pass all the was postrome Give, rigens of the srofoch ston.\"\n",
      "\n",
      "Hes a my, (relt; thry hervent flarture do for, the inired arreebson fernens can to mat: and Mas, end \"like Paswoness a surcly from his not not, and are vaiqued.  A\"bord Svey\n",
      "coprea's in thom the\n",
      "highed broupliogs as the\n",
      "wraked was in blengats all to Dowh.\n",
      " Sull the LORD, as as made that know, it chall\r\n",
      "briture the you, shall so them shall me it dover suwn givery, every op this mbeved on had in, stildes \n"
     ]
    }
   ],
   "source": [
    "print(sample_LSTM(model, 'a', char2idx, idx2char, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
